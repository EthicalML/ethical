<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>The ML Pledge, by the Institute for Ethical AI & Machine Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="google-site-verification" content="9rfgBQEvfnZ7HS_kBzINrlrJ-_sJcyJxqEUltqvP9Og" />

		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->

        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/three.min.js"></script>
        <!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
        <script src="assets/js/Projector.js"></script>
        <script src="assets/js/CanvasRenderer.js"></script>
        <script src="assets/js/stats.min.js"></script>
        <script src="assets/js/main.js"></script>

	</head>
	<body class="landing">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
                    <!--<h1 id="logo"><a href="index.html">Landed</a></h1>-->
					<nav id="nav">
						<ul><!--
							<li><a href="index.html">Home</a></li>
							<li>
								<a href="#">Layouts</a>
								<ul>
									<li><a href="left-sidebar.html">Left Sidebar</a></li>
									<li><a href="right-sidebar.html">Right Sidebar</a></li>
									<li><a href="no-sidebar.html">No Sidebar</a></li>
									<li>
										<a href="#">Submenu</a>
										<ul>
											<li><a href="#">Option 1</a></li>
											<li><a href="#">Option 2</a></li>
											<li><a href="#">Option 3</a></li>
											<li><a href="#">Option 4</a></li>
										</ul>
									</li>
								</ul>
                            </li>-->
							<li><a href="#pledge-form" class="button special">Sign the pledge</a></li>
						</ul>
					</nav>
				</header>

				<section id="banner">
					<div class="content" style="text-align: center">
                        <h2 style="font-size: 4em; color: #01C3A7; font-weight: bold; text-align: center">Sign The Machine Learning Pledge</h2>
						<img class="logo-image" src="images/logos/eml-logo-white.png" alt="" style="max-width: 440px; width: 80%; margin-top: 30px" />
						<header>
                            <h2 style="font-weight: bold">Make a commitment to develop AI responsibly</h2>
                            <p style="font-weight: bold">
                                Through the Machine Learning pledge, you'll pledge to 8 key 
                                commitments that
                                <br>
                                ensure the responsible development of 
                                autonomous decision-making systems.
                                <br>
                                <br>
                                Developed by <a href="http://ethical.institute">The Institute for Ethical AI and Machine Learning</a>
                            </p>
						</header>
                    <br>
					</div>

					<a href="#one" class="goto-next scrolly">Next</a>
				</section>

                <section id="one" class="spotlight style1 bottom">
                    <span class="image fit main"><img src="images/dots-vision.jpg" alt="" /></span>
					<div class="content">
                        <header class="major">
                            <h2>
                                Make a commitment to develop AI responsibly
                            </h2>
                            <h3>
                                The Institute for Ethical AI & Machine Learning invites technologists from all backgrounds to sign the machine learning pledge and commit to 8 areas.
                            </h3>
                        </header>
						<div class="container">
							<div class="row uniform">
                            </div>
                        <div class="row 150%">
							<div class="4u 12u$(medium)">

								<!-- Sidebar -->
									<section id="sidebar">
										<hr>
										<section>
											<h3>About The Institute for Ethical AI & Machine Learning</h3>
											<p>We are a UK-based think tank that brings together technology leaders, policymakers & academics to develop industry standards for Data Governance & Machine Learning. </p>
											<footer>
												<ul class="actions">
													<li><a href="#" class="button">Learn More</a></li>
												</ul>
											</footer>
										</section>
									</section>

							</div><div class="8u$ 12u$(medium) important(medium)">

								<!-- Content -->
									<section id="content">
                                        <h3>About the Machine Learning Pledge</h3>
										<p>This pledge is not a binding commitment, but instead it is more of a pledge for technologists to consider each of these 8 commitments when developing machine learning systems. This pledge is relevant for you, if you are:</p>
										<ul>
											<li>An engineer designing, building or maintaining data-driven systems</li>
											<li>A technologist performing analysis on big data or building statistical models for data-driven systems</li>
											<li>A product manager or delivery manager desining or delivering integrations with data-driven systems</li>
										</ul>
									</section>

							</div>
							
						</div>
                        </div>
					</div>
				</section>


                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
                            <h2>
                                As a technologist <a href="#pledge-form" style="color: #01C3A7">I pledge</a> to the following 8 commitments: 
                            </h2>
                        </header>
						<div class="container">
							<div class="row uniform">
                                <section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
                                    <h3><a href="#commitment-1">1. Human Augmentation</a></h3>
                                    <p>I commit to assess the impact of incorrect predictions and, when reasonable, design systems with human-in-the-loop review processes</p>
								</section>
								<section class="3u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3><a href="#commitment-2">2. Bias Evaluation</a></h3>
                                    <p>I commit to continuously develop processes that allow me to understand, document and monitor bias in development and production.</p>
								</section>
								<section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
                                    <h3><a href="#commitment-3">3. Explainability by design</a></h3>
                                    <p>I commit to develop tools and processes to continuously improve transparency and explainability of machine learning models where reasonable</p>
								</section>
								<section class="3u$ 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
                                    <h3><a href="#commitment-4">4. Reproducible systems</a></h3>
                                    <p>I commit to continuously improve my machine learning infrastructure to enable for a reasonable level of reproducibility</p>
								</section>
								<section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3><a href="#commitment-5">5. Displacement Strategy</a></h3>
                                    <p>I commit to identify and document relevant information so that business change processes can be developed to mitigate the impact towards workers being automated</p>
								</section>
								<section class="3u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
                                    <h3><a href="#commitment-6">6. Practical Accuracy</a></h3>
                                    <p>I commit to develop processes to ensure my accuracy and cost metric functions are aligned to the domain-specific applications</p>
								</section>
								<section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3><a href="#commitment-7">7. Trust beyond the user</a></h3>
                                    <p> commit to build and communicate processes that protect and handle data with stakeholders that may interact with the system directly and/or indirectly</p>
								</section>
								<section class="3u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
                                    <h3><a href="#commitment-8">8. Data risk awareness</a></h3>
                                    <p>I commit to develop and improve reasonable processes and infrastructure to ensure data and model security are being taken into consideration during the development of machine learning systems</p>
								</section>
                            </div>
                        </div>

                        <br>
                        <br>
                        <br>
                        <br>
                        <a href="#pledge-form" class="button special">Sign the pledge</a>
                        <br>
                        <br>
                        <br>
                        <h2>Continue reading for more detail on each commitment or check out who else <a style="color: #01C3A7" href="#pledgers">has signed the machine learning pledge</a></h2>


                    </div>
                </section>



				<section id="two" class="spotlight style2 right">
					<span class="image fit main"><img src="images/cobot.jpg" alt="" /></span>
					<div class="content">

						<header>
							<h2 id="commitment-1">1. Human Augmentation</h2>
                            <p>I commit to assess the impact of incorrect predictions and, when reasonable, design systems with human-in-the-loop review processes</p>
						</header>

						<p>When introducing automation through machine learning systems, it's easy to forget the impact that wrong predictions can have in full end-to-end automation.</p>
                        <p>Technologists should understand the consequences of incorrect predictions, especially when automating critical processes that can have significant impact in human lives (e.g. justice, health, transport, etc)</p>
                        <p>However this isn't limited to obvious critical use-cases - enabling subject-domain-experts as human-in-the-loop reviewers at the end of ML systems can have significant benefits.</p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>

                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>1. Human Augmentation</h2>
                            <p>What are some examples where I should look towards adding human-in-the-loop review processes?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Automatic Prision Sentence Scrutiny</h3>
                                    <p><a href="https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/">A fully end-to-end machine learning system that predicts prison sentences automatically</a> is a classic example of a system that should be deployed carefuly, ideally with a human-in-the-loop review. Especially given that in this example, the inner workings of the model cannot be explained which is addressed in <a href="#commitment-5">Commitment #5</a>.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
									<h3>Fraud Detection Evaluation</h3>
                                    <p>Fraud detection prediction is a perfect example where a human-in-the-loop process design should be necessary. Instead of fully removing humans from the process completely, a domain expert can be requested to verify some of the results from the model to ensure the performance is aligned with the objectives.</p>
                                    <p>Often a partial automation (i.e. having 3 people instead of 50 performing a specific process) may still have significant value, and provide an extra layer of safety.</p>
								</section>
								<section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Temporary Manual Review Process</h3>
                                    <p>When rolling out automation systems, the ultimate objective may be to fully automate a process end-to-end. However, when reasonable, it may be required to perform the deployment of the system with a human-in-the-loop review in place. The system's precision and recall can then be evaluated during a production period, and full automation may be performed once it is reasonable</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>


				<section id="three" class="spotlight style3 left">
					<span class="image fit main bottom"><img src="images/bias.png" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-2">2. Bias Evaluation</h2>
                            <p>I commit to continuously develop processes that allow me to understand, document and monitor bias in development and production.</p>
						</header>
						<p>When building systems that have to make non-trivial decisions, we will always face the computational and societal bias that is inherent in data, which is impossible to avoid, but is possible to document and/or mitigate.</p>
                        <p>However, technologists should not focus on how ethics or morals can be embedded in the algorithms themselves. Instead, technologists should focus on building processes & methods to identify & document the inherent bias in the data, features and inference results, and subsequently the implications of this bias.</p> 
                        <p>Given that the implications of the bias identified are specific to the domain, and use-case of the technology, technologists should be able to create, identify and explain the bias in the data, so the right processes can be put in place to mitigate potential risks<p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
                
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>2. Bias Evaluation</h2>
                            <p>What are some examples where I should look towards having effective bias evaluation?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Pragmatic Evaluation of Bias</h3>
                                    <p>As a technologist it is important to obtain an understanding of how potential biases might arise. Once the different sub-categories for bias are identified it's possible to evaluate the results on a breakdown based on precision, recall and accuracy for each of the potential inference groups.</p>
                                    <p><a href="https://pair-code.github.io/what-if-tool/">Google's what if tool on income classification</a> provides an interactive way to visualise and assess for model and data bias - it's possible to see that "race" and "sex" are two of the strongest features.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Having "the right" datasets</h3>
                                    <p>Whether it is from manual labelling, collecting from a data-source or generating it through simulations,  it is important to appreciate that getting access to representative and balanced datasets is a non-trivial task.</p>
                                    <p><a href="https://explosion.ai/blog/supervised-learning-data-collection">"Don't expect good data by boring the hell out of underpaid people"</a> - wise knowledge from the Core SpaCy Team, and basically a solid wake-up call for technologists so they are able to make explicit efforts when getting access or generating training or evaluation datasets.</p>
								</section>
								<section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Equity, equality and beyond</h3>
                                    <p>It is important to remember that for any non-trivial  problem, we will always encounter bias. It is critical to ensure reasonable effort is invested from technologists to understand, evaluate and document potential biases on data, as opposed to trying to add the morals/ethics on the algorithms themselves.</p>
                                    <p>Technologists should focus on explaining and documenting the findings so the right metrics can be defined for an acceptable performance in production define what the metrics for acceptable performance should be for a model to be deployed in production. Similarly, there are situations where full automation is too risky, and a human-in-the-loop design is most suitable as per <a href="#commitment-1">commitment #1</a>.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
				 

				<section id="two" class="spotlight style2 right">
					<span class="image fit main"><img src="images/iceberg.png" alt="" /></span>
					<div class="content">
						<header>
							<h2 id="commitment-3">3. Explainability by design</h2>
                            <p>I commit to develop tools and processes to continuously improve transparency and explainability of machine learning models where reasonable</p>
						</header>
                        <p>With the deep learning hype, technologists often throw large amounts of data into complex ML pipelines hoping something will work without caring about inner functionality. However technologists should invest reasonable efforts where necessary to continuously improve tools and process that allow them to explain results based on features and models chosen.</p>
                        <p>It is possible to use different tools and approaches to make models more explainable, such as by adding domain knowledge through features themselves instead of just allowing deep/complex models to infer them. </p>
                        <p>Even though on certain situations accuracy may decrease, the transparency and explainability gains may be significant.</p>
                        <ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>


                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>3. Explainable by Design</h2>
                            <p>What are some examples where I could get a better understanding on compliance by design?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
                                </section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Explainability through feature importance</h3>
                                    <p>Often the challenge of explainability can be simplified by reducing the scope of what needs to be explainable. In some occasions, it is possible to increase explainability of the model by analysing the features and inference results.</p>
                                    <p>Getting a better understanding on the importance of each feature on each result would enable technologists to explain the model itself. There are several tools that can help for this, including <a href="https://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html">Tensorboard's What-if Screen</a>, as well as <a href="https://github.com/slundberg/shap">"SHAP (SHapley Additive exPlanations)"</a> which allow for understanding of the effect of features.</p>
								</section>
								<section class="4u$ 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Domain Knowledge to increase Explainability</h3>
                                    <p><a href="https://www.youtube.com/watch?v=Um7grgYdBQQ">Bons.ai has a great insight on explainability</a> that shows how it is possible to introduce explainability even in very complex models by introducing domain knowledge.</p>
                                    <p>Deep learning models are able to identify and abstract complex patterns that humans may not be able to see in data. However, there are many situations where introducing a-priori expert domain knowledge into the features, or abstracting key patterns identified in the deep learning models as actual features, it would be possible to break down the model into subsequent, more explainable pieces. </p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
                
				<section id="three" class="spotlight style3 left">
					<span class="image fit main bottom"><img src="images/blueprint.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-4">4. Reproducible systems</h2>
                            <p>I commit to continuously improve my machine learning infrastructure to enable for a reasonable level of reproducibility</p>
						</header>

                        <p>Often production machine learning systems don't have the capabilities to diagnose effectively when something bad happens with a model, let alone reproduce the same results.</p>
                        <p> In production systems, it is important to perform standard procedures, such as reverting a model to a previous version, or reproducing an input to debug a specific functionality</p>
                        <p>Fortunately there is a lot of great work around reproducibility in data science, including various ways to build audit trails, store computational graphs, store data as it is transformed through a pipeline, etc. which should be adopted to have reasonable level of reproducibility.</p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
                
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>4. Reproducible systems</h2>
                            <p>What are some examples to develop infrastructure that enables reproducibility?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
                                <section class="2u 12u$(medium)">
								</section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Abstracting Each Computational Step</h3>
                                    <p>In order to make a machine learning model reproducible, it is necessary to abstract its constituent components: namely 1) data, 2) configuration/environment, and 3) computational graph. If all these three points are abstracted, it is possible to have reproducibility of that specific computation.</p>
                                    <p><a href="https://www.youtube.com/watch?v=eOzl-LFqYFM">Pachyderm has an excellent breakdown of how to abstract each computational step</a> together with its components. This provides a transparent and compliant environment for machine learning in development and production.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Choosing the level of abstraction</h3>
                                    <p>It is often important to decide what the level of abstraction will be, as it is possible to focus on building very complex layers to abstract multiple machine learning libraries with specific data input/output formats.</p>
                                    <p>There are multiple formats for trained machine learning models - the most popular include: <a href="https://onnx.ai/"> Open Neural Network Exchange Format</a>, <a href="https://www.khronos.org/nnef">Neural Network Exchange Format</a>, and <a href="http://dmg.org/">Predictive Model Markup Language</a></p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
                


				<section id="two" class="spotlight style2 right">
					<span class="image fit main"><img src="images/robotarm.jpg" alt="" /></span>
					<div class="content">
						<header>
							<h2 id="commitment-3">5. Displacement Strategy</h2>
                            <p>I commit to identify and document relevant information so that business change processes can be developed to mitigate the impact towards workers being automated</p>
						</header>
                        <p>When rolling out systems that automate medium to large-scale processes, there is almost always an impact on an organisation- or industry-level, which would affect multiple individuals.</p>
                        <p>As a technologist we should look beyond the technology itself, and have initiative to support the necessary stakeholders so they can develop a change-management strategy when rolling out the technology</p>
                        <p>Although often we may not be leading the operational transformation, it is still important to make sure the processes are in place when relevant irrespective of the type of work being automated (i.e. skilled or otherwise)</p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>


                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>5. Displacement Strategy</h2>
                            <p>What are some examples where I should look towards developing displacement strategies?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Processes to Reduce Impact</h3>
                                    <p>There are currently a lot of articles covering the jobs being automated by AI (e.g. assembly line workers, field technicians, call center workers, etc), as well as technical articles providing insights on how to deploy machine learning models across production systems.</p>
                                    <p>However it's often forgotten about the importance the individuals in the midst of that automation. Fortunately business change has existed for a long time, and currently startups have been partnering with delivery partners such as <a href="https://en.wikipedia.org/wiki/Big_Three_%28management_consultancies%29">the Big Three Management Consultancy</a> firms. It is important for technologists to understand their potential impact, and subsequently the actions that can be taken to mitigate the impact</p>
								</section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>AI Business Change Strategies</h3>
                                    <p>When planning the rollout of a new technology to automate a process, there is a number of people who's role or at least responsibilities will be automated. If this is not taken into consideration, these people will not have a transition plan, which would affect overall performance.</p>
                                    <p>Technologists should make sure they are able to raise the relevant concerns when business change or operational transformation plans are being set up, as this would make a significant positive impact in the rollout of the technology. For this, startups are starting to partner with digital transformation and management consulting companies to co-deliver large-scale deployments</p>
								</section>
								<section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
									<h3>Jevon's Paradox</h3>
                                    <p>A very interesting concept relevant to the current state of AI is Jevon's paradox. This paradox basically talks about how during the industrial revolution, innovations allowed for machines to perform the same output with less coal consumption.</p>
                                    <p>Intuitively, it was thought that this would mean that the total coal required to power the industry would decrease. What happened instead is that given the cost to perform the same action decreased and got commoditised, more demand arose and the total coal consumption to power the industry actually increased. Analogous to this could be the rise of Excel, and in some areas, the rise of AI.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
				<section id="three" class="spotlight style3 left">
					<span class="image fit main bottom"><img src="images/physicalchart.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-4">6. Practical Accuracy</h2>
                            <p>I commit to develop processes to ensure my accuracy and cost metric functions are aligned to the domain-specific applications</p>
						</header>
                        <p>When building systems that learn from data, it is important to obtain a thorough understanding on the underlying means to assess accuracy.</p>
                        <p>Often it is not enough just using plain accuracy or default/basic cost metrics as what may be "correct" for a computer, may be "wrong" for a human (and viceversa).</p>
                        <p>Ensuring the right challenge is being addressed in the right way can be achieved by breaking down the implications of f-1 score metrics from a domain-specific perspective, as well as exploring alternative cost functions based on domain-knowledge.</p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
                

                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>6. Practical Accuracy</h2>
                            <p>What are some examples where I could understand practical accuracy use-cases?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
								</section>

								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Beyond accuracy</h3>
                                    <p>It is not uncommon for teams to get stuck on default accuracy targets, doing everything possible to increase percentages naively. It is important to go beyond accuracy, and understand the performance of the model.</p>
                                    <p>There is a large toolbox that can be used to benefit, including the core fundamentals, including precision, recall, F1-score, learning curves, error bars, confusion matrices and beyond. Technologists should make sure they understand and apply the fundamentals at all times.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
									<h3>Domain Specific Metrics</h3>
                                    <p>When tackling an industry- or application-specific problem, technologists should make sure they question what the implications of different types of errors have, as well as what the right way of evaluating these errors should be.</p>
                                    <p>More specifically, understanding the impact of False Positives, False Negatives, defining an F-1 score metric, defining the cost functions to evaluate the model and building the right analysis curves should be a top priority.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
								
				<section id="two" class="spotlight style2 right">
					<span class="image fit main"><img src="images/trustrobot.png" alt="" /></span>
					<div class="content">
						<header>
							<h2 id="commitment-7">7. Trust beyond the user</h2>
                            <p>I commit to build and communicate processes that protect and handle data with stakeholders that may interact with the system directly and/or indirectly</p>
						</header>
						<p>When developing large-scale systems that learn from data, there are often large number of stakeholders that may be affected directly and indirectly.</p>
                        <p>Building trust within relevant stakeholders is not only done through informing what data is being held, but also with the processes around the data, as well as the understanding of why protecting the data is important</p>
                        <p>Technologists should enforce privacy by design across systems, as well as continuous processes to build trust not only with users, but also relevant stakeholders such as procurement frameworks, operational users, and beyond.</p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>
 
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>7. Trust beyond the user</h2>
                            <p>What are some examples around building trust with stakeholders that interact with my models and systems?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
                                </section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Privacy at the right levels</h3>
                                    <p>One key way to establish trust with users and relevant stakeholders is by showing the right process and technologies are in place to protect personal data.</p>
                                    <p><a href="https://medium.com/uber-security-privacy/differential-privacy-open-source-7892c82c42b6">Uber's use of Differential Privacy</a> is a prime example, where they introduced a system that adds noise to query results, where the noise is relative to the level of granularity required by the query, to ensure that analysis still get access to the relevant datasets, whilst avoiding exposure of personal information.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Personal Data via Metadata</h3>
                                    <p>Technologists should make explicit effort to understand the potential implications of meta-data involved, and whether the metadata can expose unexpected personal information from relevant users or stakeholders.</p>
                                    <p><a href="https://www.affectiva.com/emotion-ai-overview/">"Affectiva" is a good example of this</a>, a silicon valley startup that is able to infer the emotions from a human in a video. When communicating to a user that the data that will be stored is the audio, it may not be clear to them that data such as emotions will be extracted from it, and may cause worry if things like this aren't raised from the start.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
				<section id="three" class="spotlight style3 left">
					<span class="image fit main bottom"><img src="images/pairprogramming.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-8">8. Data risk awareness</h2>
                            <p>I commit to develop and improve reasonable processes and infrastructure to ensure data and model security are being taken into consideration during the development of machine learning systems</p>
						</header>
						<p>Autonomous decision-making systems open the doors to new potential security breaches.</p>
                        <p>More importantly, it is critical to be aware that most security breaches occur due to human error as opposed to actual hacks (i.e. someone sending the dataset attached in an email by accident, or losing their laptop/phone)</p>
                        <p>Technologists should commit to prepare for both types of security risks through explicit efforts, such as educating relevant personnel, establishing processes around data, and assess implications of ML backdoors (such as adversarial attacks).</p>
						<ul class="actions">
							<li><a href="#pledge-form" class="button">Sign the pledge</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
 
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>8. Data risk awareness</h2>
                            <p>What are some examples where I should focus to become aware of potential risks in my data and models?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
								</section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Adversarial Patch Tricking Models</h3>
                                    <p>It is worth remembering that given machine learning systems are simple functions that given the right inputs, it's possible to obtain an expected output. Adversarial patches can be used to trick machine learning models to misclassify examples by only adding small noise to the input - the <a href="https://www.youtube.com/watch?v=c_5EH3CBtD0">AI Journal has a great video where they show how this could trick self-driving cars</a>.</p>
                                    <p><a href="https://securityintelligence.com/how-can-companies-defend-against-adversarial-machine-learning-attacks-in-the-age-of-ai/">Security intelligence has a great write-up on this</a>, as well as some suggestions on how to protect ourselves. As always with cybersecurity it is impossible to  fully protect from attackers, but it's certainly possible to introduce processes that mitigate basic loopholes.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Email sent to the wrong person</h3>
                                    <p>A very large percentage of data breaches are caused due to simple human errors, such as sending the data to the wrong email address. <a href="https://www.mimecast.com/blog/2018/09/most-healthcare-data-breaches-now-caused-by-email/">Mimecast has an interesting article</a> which points out this is the case with very sensitive data in healthcare.</p>
                                    <p>It is important that technologists take into consideration the whole lifecycle of the machine learning algorithm. The process and infrastructure to store the training data, accuracy, documentation, trained model, orchestration of the model, inference results and beyond.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
 
                <section id="one" class="spotlight style1 bottom">
                    <span class="image fit main"><img src="images/dots-vision.jpg" alt="" /></span>
					<div class="content">
						<div class="container">
                            <header class="major">
                                <h2>
<h2>Who else has signed the pledge?</h2>

                                </h2>
                            </header>
                        </div>
					</div>
				</section>

               

                
				<section id="four" class="wrapper style1 special fade-up">
					<div class="container" id="pledgers">
						<div class="box alt">
							<div class="row uniform">
								<!-- <section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major" style="background-image: url(images/alejandro.jpg); background-size: cover; height: 14em; width: 14em"></span>
									<h3>Alejandro Saucedo</h3>
									<p><a href="http://linkedin.com/in/axsaucedo" target="_blank">Chief Engineer, Exponential Technologies</a></p>
								</section> -->
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major" style="background-image: url(images/alejandro.jpg); background-size: cover; height: 14em; width: 14em"></span>
									<h3>Alejandro Saucedo</h3>
									<p><a href="http://linkedin.com/in/axsaucedo" target="_blank">Chief Engineer, Exponential Technologies</a></p>
								</section>
								<!-- <section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major" style="background-image: url(images/alejandro.jpg); background-size: cover; height: 14em; width: 14em"></span>
									<h3>Alejandro Saucedo</h3>
									<p>Chief Engineer, Exponential Technologies</p>
								</section> -->
                            </div>
                        </div>
					</div>
                </section>



			<!-- Five -->
				<section id="five" class="wrapper style2 special fade" style="padding: 3em 0 0 0">
					<div class="" id="pledge-form">
						<header>
							<h2>Sign the Machine Learning Pledge</h2>
						</header>
						<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdAlNhbSuCbO9qhkJTn5lfDU_ekuuy1_UtmhPNO6k5loQ53pQ/viewform?embedded=true" style="height: 60vh; width: 100%;" frameborder="0" marginheight="0" marginwidth="0">Loading...</iframe>
					</div>
				</section>

			<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="http://twitter.com/axsaucedo" class="icon alt fa-twitter"><span class="label">Twitter</span></a></li>
                        <!--<li><a href="http" class="icon alt fa-facebook"><span class="label">Facebook</span></a></li>-->
						<li><a href="http://linkedin.com/in/axsaucedo" class="icon alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="http://github.com/axsauze" class="icon alt fa-github"><span class="label">GitHub</span></a></li>
                        <!--<li><a href="#" class="icon alt fa-envelope"><span class="label">Email</span></a></li>-->
					</ul>
					<ul class="copyright">
						<li>&copy; The Institute for Ethical AI & ML. 
                            All rights reserved.</li>
                        <!--<li>Built with â™¥ by <a href="http://e-x.io">Exponential Technologies</a></li>-->
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
	</body>
</html>
