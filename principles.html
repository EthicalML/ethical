<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>The 8 principles for responsible development of AI & Machine Learning systems</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="google-site-verification" content="9rfgBQEvfnZ7HS_kBzINrlrJ-_sJcyJxqEUltqvP9Og" />
        <meta name="author" content="The Institute for Ethical Ai & Machine Learning">
        <meta name="description" content="The 8 principles for responsible development of AI & Machine Learning systems.">
        <link rel="canonical" href="https://ethical.institute">
        <link rel="icon" href="images/logos/eml-logo-white.png">



        <!-- FACEBOOK -->
        <meta property="og:url" content="https://ethical.institute">
        <meta property="og:type" content="website">
        <meta property="og:title" content="The Machine Learning Principles">
        <meta property="og:description" content="The 8 principles for responsible development of AI & Machine Learning systems">
        <meta property="og:image" content="https://ethical.institute/images/principles.jpg">



        <!-- THE TWITTER -->
        <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@EthicalML">
        <meta name="twitter:creator" content="@EthicalML">
        <meta name="twitter:title" content="The Machine Learning Principles">
        <meta name="twitter:description" content="The 8 principles for responsible development of AI & Machine Learning systems">
        <meta name="twitter:image:src" content="https://ethical.institute/images/principles.jpg">


        <!-- G++ -->
        <meta itemprop="name" content="The Machine Learning Principles">
        <meta itemprop="description" content="Advancing industries through the intelligence revolution">
        <meta itemprop="image" content="https://ethical.institute/images/principles.jpg">




		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->

        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/jquery.dropotron.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/three.min.js"></script>
        <!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
        <script src="assets/js/Projector.js"></script>
        <script src="assets/js/CanvasRenderer.js"></script>
        <script src="assets/js/stats.min.js"></script>
        <script src="assets/js/main.js"></script>

	</head>
	<body class="landing">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
                    <h1 id="logo"><a href="index.html"><img src="images/logos/eml-logo-white.png" height="15px"> The Institute for Ethical AI & Machine Learning</a></h1>
					<nav id="nav">
						<ul style="font-weight: bold">
							<li><a href="index.html">Home</a></li>
							<li>
                            <a href="principles.html">Principles</a>
                            <ul>
                                <li><a href="principles.html#commitment-1">#1 Human Augmentation</a></li>
                                <li><a href="principles.html#commitment-2">#2 Bias Evaluation</a></li>
                                <li><a href="principles.html#commitment-3">#3 Explainability</a></li>
                                <li><a href="principles.html#commitment-4">#4 Reproducible Operations</a></li>
                                <li><a href="principles.html#commitment-5">#5 Displacement Strategy</a></li>
                                <li><a href="principles.html#commitment-6">#6 Practical Accuracy</a></li>
                                <li><a href="principles.html#commitment-7">#7 Trust by Privacy</a></li>
                                <li><a href="principles.html#commitment-8">#8 Security Risks</a></li>
                            </ul>
                            <li>
                                <a href="rfx.html">AI-RFX Framework</a>
                            </li>
                            <li>
                                <a href="xai.html">Explainable AI</a>
                                <ul>
                                    <li><a href="xai.html">XAI Framework</a></li>
                                    <li><a href="https://github.com/EthicalML/awesome-machine-learning-operations">Machine Learning Operations List</a></li>
                                </ul>
                            </li>
                            <li>
                                <a href="mle.html">Newsletter</a>
                            </li>
	
                            </li>
							<li><a href="#contact" class="button special">Contact us or Join</a></li>
						</ul>
					</nav>
				</header>

				<section id="banner" style="font-size: 11pt">
					<div class="content" style="text-align: center">
                        <h2 style="font-size: 4em; color: #01C3A7; font-weight: bold; text-align: center; line-height: 1.3em; margin-bottom: 20px">The Responsible Machine Learning Principles</h2>
						<img class="logo-image" src="images/logos/eml-logo-white.png" alt="" style="max-width: 440px; width: 80%; margin-top: 30px" />
						<header>
                            <h2 style="font-weight: bold; margin-top:0px">A practical framework to develop AI responsibly</h2>
                            <p style="font-weight: bold; max-width: 850px">
                                The 8 principles of responsible ML development provide a practical framework to support technologists when designing, developing or maintaining systems that learn from data.
                                <br>
                                <br>
                                If these principles resonate with you, you invite you to join the <a href="index.html#contact">Ethical ML Network (BETA)</a>, and be part of a global network of leaders driving forward positive change in this area.
                            </p>
						</header>
                    <br>
					</div>

					<a href="#one" class="goto-next scrolly">Next</a>
				</section>

                <section id="one" class="spotlight style1 bottom">
                    <span class="image fit main"><img src="images/dots-vision.jpg" alt="" /></span>
					<div class="content">
                        <header class="major">
                            <h2>
                                The Responsible Machine Learning Principles
                            </h2>
                            <h3>
                                The Responsible Machine Learning Principles are a practical framework put together by domain experts.
                                <br>Their purpose is to provide guidance for technologists to develop machine learning systems responsibly.
                                <br>
                                <br>
                            </h3>
                        </header>
					</div>
				</section>


                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
                        <div class="container">
							<div class="row uniform">
                                <section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-cog"></span>
                                    <h3><a href="#commitment-1">1. Human augmentation</a></h3>
                                    <p>I commit to assess the impact of incorrect predictions and, when reasonable, design systems with human-in-the-loop review processes</p>
								</section>
								<section class="3u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-pie-chart"></span>
                                    <h3><a href="#commitment-2">2. Bias evaluation</a></h3>
                                    <p>I commit to continuously develop processes that allow me to understand, document and monitor bias in development and production.</p>
								</section>
								<section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-info-circle"></span>
                                    <h3><a href="#commitment-3">3. Explainability by justification</a></h3>
                                    <p>I commit to develop tools and processes to continuously improve transparency and explainability of machine learning systems where reasonable.</p>
								</section>
								<section class="3u$ 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
                                    <h3><a href="#commitment-4">4. Reproducible operations</a></h3>
                                    <p>I commit to develop the infrastructure required to enable for a reasonable level of reproducibility across the operations of ML systems.</p>
								</section>
								<section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-group"></span>
                                    <h3><a href="#commitment-5">5. Displacement strategy</a></h3>
                                    <p>I commit to identify and document relevant information so that business change processes can be developed to mitigate the impact towards workers being automated.</p>
								</section>
								<section class="3u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-bar-chart"></span>
                                    <h3><a href="#commitment-6">6. Practical accuracy</a></h3>
                                    <p>I commit to develop processes to ensure my accuracy and cost metric functions are aligned to the domain-specific applications.</p>
								</section>
								<section class="3u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-commenting-o"></span>
                                    <h3><a href="#commitment-7">7. Trust by privacy</a></h3>
                                    <p>I commit to build and communicate processes that protect and handle data with stakeholders that may interact with the system directly and/or indirectly.</p>
								</section>
								<section class="3u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-exclamation-triangle"></span>
                                    <h3><a href="#commitment-8">8. Data risk awareness</a></h3>
                                    <p>I commit to develop and improve reasonable processes and infrastructure to ensure data and model security are being taken into consideration during the development of machine learning systems.</p>
								</section>
                            </div>
                        </div>

                        <br>
                        <br>
                        <br>
                        <br>
                        <h2>Continue reading for more detail on each principle</h2>


                    </div>
                </section>



				<section id="two" class="spotlight style2 right stylelong">
					<span class="image fit main"><img src="images/robothand.png" alt="" /></span>
					<div class="content">

						<header>
							<h2 id="commitment-1">1. Human augmentation</h2>
                            <p>I commit to assess the impact of incorrect predictions and, when reasonable, design systems with human-in-the-loop review processes.</p>
						</header>

						<p>When introducing automation through machine learning systems, it's easy to forget the impact that wrong predictions can have in full end-to-end automation.</p>
                        <p>Technologists should understand the consequences of incorrect predictions, especially when automating critical processes that can have significant impact in human lives (e.g. justice, health, transport, etc).</p>
                        <p>However this isn't limited to obvious critical use-cases - enabling subject-domain-experts as human-in-the-loop reviewers at the end of ML systems can have significant benefits.</p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>

                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>1. Human augmentation</h2>
                            <p>What are some examples where I should look towards adding human-in-the-loop review processes?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Automatic prision sentence scrutiny</h3>
                                    <p><a href="https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/">A fully end-to-end machine learning system that predicts prison sentences automatically</a> is a classic example of a system that should be deployed carefuly, ideally with a human-in-the-loop review. Especially given that in this example, the inner workings of the model cannot be explained which is addressed in <a href="#commitment-5">Commitment #5</a>.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
									<h3>Fraud detection evaluation</h3>
                                    <p>Fraud detection prediction is a perfect example where a human-in-the-loop process design should be necessary. Instead of fully removing humans from the process completely, a domain expert can be requested to verify some of the results from the model to ensure the performance is aligned with the objectives.</p>
                                    <p>Often a partial automation (i.e. having 3 people instead of 50 performing a specific process) may still have significant value, and provide an extra layer of safety.</p>
								</section>
								<section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Temporary manual review process</h3>
                                    <p>When rolling out automation systems, the ultimate objective may be to fully automate a process end-to-end. However, when reasonable, it may be required to perform the deployment of the system with a human-in-the-loop review in place. The system's precision and recall can then be evaluated during a production period, and full automation may be performed once is deemed acceptable.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>


				<section id="three" class="spotlight style3 left stylelong">
					<span class="image fit main bottom"><img src="images/bias.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-2">2. Bias evaluation</h2>
                            <p>I commit to continuously develop processes that allow me to understand, document and monitor bias in development and production.</p>
						</header>
						<p>When building systems that have to make non-trivial decisions, we will always face the computational and societal bias that is inherent in data, which is impossible to avoid, but is possible to document and/or mitigate.</p>
                        <p>However we should take a step back from only trying to embed ethics directly into the algorithms themselves. Instead, technologists should focus on building processes & methods to identify & document the inherent bias in the data, features and inference results, and subsequently the implications of this bias.</p> 
                        <p>Given that the implications of the bias identified are specific to the domain, and use-case of the technology, technologists should be able to create, identify and explain the bias in the data and features, so the right processes can be put in place to mitigate potential risks.<p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
                
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>2. Bias evaluation</h2>
                            <p>What are some examples where I should look towards having effective bias evaluation?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Pragmatic evaluation of bias</h3>
                                    <p>As a technologist it is important to obtain an understanding of how potential biases might arise. Once the different sub-categories for bias are identified it's possible to evaluate the results on a breakdown based on precision, recall and accuracy for each of the potential inference groups.</p>
                                    <p><a href="https://pair-code.github.io/what-if-tool/">Google's what if tool on income classification</a> provides an interactive way to visualise and assess for model and data bias - it's possible to see that "race" and "sex" are two of the strongest features.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Having "the right" datasets</h3>
                                    <p>Whether it is from manual labelling, collecting from a data-source or generating it through simulations,  it is important to appreciate that getting access to representative and balanced datasets is a non-trivial task.</p>
                                    <p><a href="https://explosion.ai/blog/supervised-learning-data-collection">"Don't expect good data by boring the hell out of underpaid people"</a> - wise knowledge from the Core SpaCy Team, and basically a solid wake-up call for technologists so they are able to make explicit efforts when getting access or generating training or evaluation datasets.</p>
								</section>
								<section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Equity, equality and beyond</h3>
                                    <p>The deployment of a biased system, can have the effect of reinforcing that pre-existing societal bias (<a href="https://www.oii.ox.ac.uk/videos/does-ai-have-gender/">Professor Gina Neff provides an insight in her talk</a>), "Does AI Have Gender?". It is certainly possible for the system to be configured in such a way that it works towards reduing that bias. </p>
                                    <p>However this is an extremely sensitive and complex issue. For example, do we want to configure the system for equality? or for equity? These decisions should not be taken lightly. For most (if not all) cases, the decision should be beyond the technologists themselves.</p>
                                    <p>Because of reasons like this, this commitment encourages technologists to focus on identifying and documenting the biases present together with their potential impact. Ethical decisions should be considered together with the relevant industry stakeholders (ethics boards, regulatory bodies, etc).</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
				 

				<section id="two" class="spotlight style2 right stylelong">
					<span class="image fit main"><img src="images/iceberg.png" alt="" /></span>
					<div class="content">
						<header>
							<h2 id="commitment-3">3. Explainability by justification</h2>
                            <p>I commit to develop tools and processes to continuously improve transparency and explainability of machine learning models where reasonable.</p>
						</header>
                        <p>With the deep learning hype, technologists often throw large amounts of data into complex ML pipelines hoping something will work, without understanding how the pipelines work internally. However technologists should invest reasonable efforts where necessary to continuously improve tools and process that allow them to explain results based on features and models chosen.</p>
                        <p>It is possible to use different tools and approaches to make ML systems more explainable, such as by adding domain knowledge through features themselves instead of just allowing deep/complex models to infer them. </p>
                        <p>Even though on certain situations accuracy may decrease, the transparency and explainability gains may be significant.</p>
                        <ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>


                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>3. Explainable by justification</h2>
                            <p>What are some examples where I could get a better understanding on compliance by design?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
                                </section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Explainability through feature importance</h3>
                                    <p>Often the challenge of explainability can be simplified by reducing the scope of what needs to be explainable. In some occasions, it is possible to increase explainability of the model by analysing the features and inference results.</p>
                                    <p>Getting a better understanding on the importance of each feature on each result would enable technologists to explain the model itself. There are several tools that can help for this, including <a href="https://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html">Tensorboard's What-if Screen</a>, as well as <a href="https://github.com/slundberg/shap">"SHAP (SHapley Additive exPlanations)"</a> which allow for understanding of the effect of features.</p>
								</section>
								<section class="4u$ 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Domain knowledge to increase explainability</h3>
                                    <p><a href="https://www.youtube.com/watch?v=Um7grgYdBQQ">Bons.ai has a great insight on explainability</a> that shows how it is possible to introduce explainability even in very complex models by introducing domain knowledge.</p>
                                    <p>Deep learning models are able to identify and abstract complex patterns that humans may not be able to see in data. However, there are many situations where introducing a-priori expert domain knowledge into the features, or abstracting key patterns identified in the deep learning models as actual features, it would be possible to break down the model into subsequent, more explainable pieces. </p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
                
				<section id="three" class="spotlight style3 left stylelong">
					<span class="image fit main bottom"><img src="images/blueprint.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-4">4. Reproducible operations</h2>
                            <p>I commit to develop the infrastructure required to enable for a reasonable level of reproducibility across the operations of ML systems.</p>
						</header>

                        <p>Often production machine learning systems don't have the capabilities to diagnose or respond effectively when something bad happens with a model, let alone reproduce the same results.</p>
                        <p> In production systems, it is important to perform standard procedures, such as reverting a model to a previous version, or reproducing an input to debug a specific functionality, which introduces complexity in infrastructure.</p>
                        <p>There are tools and best practices for machine learning operations. These aid reproducibility of machine learning systems by proividing ways to abstract computational graphs and archive data at each step of transformation pipelines. These should be adopted to provide a reasonable level of reproducibility of operations.</p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
                
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>4. Reproducible operations</h2>
                            <p>What are some examples to develop infrastructure that enables reproducibility?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
                                <section class="2u 12u$(medium)">
								</section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Abstracting each computational step</h3>
                                    <p>In order to make a machine learning model reproducible, it is necessary to abstract its constituent components: namely 1) data, 2) configuration/environment, and 3) computational graph. If all these three points are abstracted, it is possible to have a basis for model reproducibility.</p>
                                    <p><a href="https://www.youtube.com/watch?v=eOzl-LFqYFM">Pachyderm has an excellent breakdown of how to abstract each computational step</a> together with its components. Similarly, <a href="https://www.seldon.io/">Seldon Core</a> provides a flexible way to orchestrate the operations and serving of models in production.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Adopting Open Standards</h3>
                                    <p>It is often important to decide what the level of abstraction will be, as it is possible to focus on building very complex layers to abstract multiple machine learning libraries with specific data input/output formats.</p>
                                    <p>There are multiple formats for trained machine learning models - the most popular include: <a href="https://onnx.ai/"> Open Neural Network Exchange Format</a>, <a href="https://www.khronos.org/nnef">Neural Network Exchange Format</a>, and <a href="https://dmg.org/">Predictive Model Markup Language</a>.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
                


				<section id="two" class="spotlight style2 right stylelong">
					<span class="image fit main"><img src="images/robotarm.jpg" alt="" /></span>
					<div class="content">
						<header>
							<h2 id="commitment-3">5. Displacement strategy</h2>
                            <p>I commit to identify and document relevant information so that business change processes can be developed to mitigate the impact towards workers being automated.</p>
						</header>
                        <p>When rolling out systems that automate medium to large-scale processes, there is almost always an impact on an organisation- or industry-level, which would affect multiple individuals.</p>
                        <p>As technologists we should look beyond the technology itself, and have initiative to support the necessary stakeholders so they can develop a change-management strategy when rolling out the technology.</p>
                        <p>Although often technologists themselves may not be leading the operational transformation, it is still important to make sure the processes are in place when relevant, irrespective of the type of work being automated (i.e. skilled or otherwise).</p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>


                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>5. Displacement strategy</h2>
                            <p>What are some examples where I should look towards developing displacement strategies?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-area-chart"></span>
									<h3>Processes to reduce impact</h3>
                                    <p>There are currently a lot of articles covering the jobs being automated by AI (e.g. assembly line workers, field technicians, call center workers, etc), as well as technical articles providing insights on how to deploy machine learning models across production systems.</p>
                                    <p>However it's often forgotten about the impact to individuals that are part of processes being automated. Fortunately business change has existed for a long time, and currently startups have been partnering with delivery partners such as <a href="https://en.wikipedia.org/wiki/Big_Three_%28management_consultancies%29">the Big Three Management Consultancy</a> firms. It is important for technologists to understand their potential impact, and subsequently the actions that can be taken to mitigate the impact.</p>
								</section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
                                    <h3>Jevon's paradox</h3>
                                    <p>A very interesting concept relevant to the current state of AI is Jevon's paradox. This paradox talks about how during the industrial revolution, innovations allowed for machines to perform the same output with less coal consumption.</p>
                                    <p>Intuitively, it was thought that this would mean that the total coal required to power the industry would decrease. What happened instead is that given the cost to perform the same action decreased and got commoditised, more demand arose and the total coal consumption to power the industry actually increased. Analogous to this could be the rise of Excel, and in some areas, the rise of AI.</p>								
								</section>
								<section class="4u$ 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>AI business change strategies</h3>
                                    <p>When planning the rollout of a new technology to automate a process, there are a number of people who's role or at least responsibilities will be automated. If this is not taken into consideration, these people will not have a transition plan and it won't be possible to fully benefit from the time and resources gained from the automation.</p>
                                    <p>Technologists should make sure they are able to raise the relevant concerns when business change or operational transformation plans are being set up, as this would make a significant positive impact in the rollout of the technology.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
				<section id="three" class="spotlight style3 left stylelong">
					<span class="image fit main bottom"><img src="images/physicalchart.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-4">6. Practical accuracy</h2>
                            <p>I commit to develop processes to ensure my accuracy and cost metric functions are aligned to the domain-specific applications.</p>
						</header>
                        <p>When building systems that learn from data, it is important to obtain a thorough understanding on the underlying means to assess accuracy.</p>
                        <p>Often it is not enough just using plain accuracy or default/basic cost metrics as what may be "correct" for a computer, may be "wrong" for a human (and vice-versa).</p>
                        <p>Ensuring the right challenge is being addressed in the right way can be achieved by breaking down the implications of f-1 score metrics from a domain-specific perspective, as well as exploring alternative cost functions based on domain-knowledge.</p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
                

                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>6. Practical accuracy</h2>
                            <p>What are some examples where I could understand practical accuracy use-cases?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
								</section>

								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Beyond accuracy</h3>
                                    <p>It is not uncommon for teams to get stuck on default accuracy targets, doing everything possible to increase percentages naively. It is important to go beyond accuracy, and understand the performance of the model.</p>
                                    <p>There is <a href="https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c">a large toolbox of different approaches</a> that can be used to aid us in finding the most suitable accuracy metrics to use. This includes core fundamentals, such as precision, recall, F1-score, learning curves, error bars, confusion matrices and beyond. Technologists should make sure they understand and apply the fundamentals at all times.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
									<h3>Domain specific metrics</h3>
                                    <p>When tackling an industry or application-specific problem, technologists should make sure they question what the implications of different types of errors have, as well as what the right way of evaluating these errors should be.</p>
                                    <p>In system critical situations, there may be constraints where some types of errors are less critical than others. Similarly, there is often a lot of domain knowledge that can be abstracted in the cost functions to understand what answers may be intuitively correct to humans and how to represent these into mathematical functions.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
								
				<section id="two" class="spotlight style2 right stylelong">
					<span class="image fit main"><img src="images/trustrobot.png" alt="" /></span>
					<div class="content">
						<header>
							<h2 id="commitment-7">7. Trust by privacy</h2>
                            <p>I commit to build and communicate processes that protect and handle data with stakeholders that may interact with the system directly and/or indirectly.</p>
						</header>
						<p>When developing large-scale systems that learn from data, there are often large number of stakeholders that may be affected directly and indirectly.</p>
                        <p>Building trust within relevant stakeholders is not only done through informing what data is being held, but also with the processes around the data, as well as the understanding of why protecting the data is important.</p>
                        <p>Technologists should enforce privacy by design across systems, as well as continuous processes to build trust not only with users, but also relevant stakeholders such as procurement frameworks, operational users, and beyond.</p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#three" class="goto-next scrolly">Next</a>
				</section>
 
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>7. Trust by privacy</h2>
                            <p>What are some examples around building trust with stakeholders that interact with my models and systems?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
                                </section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Privacy at the right levels</h3>
                                    <p>One key way to establish trust with users and relevant stakeholders is by showing the right process and technologies are in place to protect personal data.</p>
                                    <p><a href="https://medium.com/uber-security-privacy/differential-privacy-open-source-7892c82c42b6">Uber's use of Differential Privacy</a> is a prime example, where they introduced a system that adds noise to query results, where the noise is relative to the level of granularity required by the query, to ensure that analysis still get access to the relevant datasets, whilst avoiding exposure of personal information.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Personal data via metadata</h3>
                                    <p>Technologists should make explicit effort to understand the potential implications of metadata involved, and whether the metadata can expose unexpected personal information from relevant users or stakeholders.</p>
                                    <p>The <a href="https://www.theguardian.com/uk-news/2018/mar/22/cambridge-analytica-scandal-the-biggest-revelations-so-far">cambridge analytica scandal</a> is the most relevant example, and a good generalisation for similar situations. Direct and in-direct users that interact with a system may give access to their data without realising the privacy breaches that could be extracted from metadata until it's too late.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
				<section id="three" class="spotlight style3 left stylelong">
					<span class="image fit main bottom"><img src="images/pairprogramming.jpg" alt="" /></span>
					<div class="content">
                        <header>
							<h2 id="commitment-8">8. Data risk awareness</h2>
                            <p>I commit to develop and improve reasonable processes and infrastructure to ensure data and model security are being taken into consideration during the development of machine learning systems.</p>
						</header>
						<p>Autonomous decision-making systems open the doors to new potential security breaches.</p>
                        <p>More importantly, it is critical to be aware that large percentage of security breaches occur due to human error as opposed to actual hacks (i.e. someone sending the dataset attached in an email by accident, or losing their laptop/phone).</p>
                        <p>Technologists should commit to prepare for both types of security risks through explicit efforts, such as educating relevant personnel, establishing processes around data, and assess implications of ML backdoors (such as adversarial attacks).</p>
						<ul class="actions">
							<li><a href="index.html#contact" class="button">Join the network</a></li>
						</ul>
					</div>
					<a href="#four" class="goto-next scrolly">Next</a>
				</section>
 
                <section id="four" class="wrapper style1 special fade-up">
					<div class="container">
						<header class="major">
							<h2>8. Security risks</h2>
                            <p>What are some examples where I should focus to become aware of potential risks in my data and models?</p>
						</header>
						<div class="box alt">
							<div class="row uniform">
								<section class="2u 12u(medium)">
								</section>
								<section class="4u 6u(medium) 12u$(xsmall)">
									<span class="icon alt major fa-flask"></span>
									<h3>Adversarial patch tricking models</h3>
                                    <p>It is worth remembering that given machine learning systems are simple functions that given the right inputs, it's possible to obtain an expected output. Adversarial patches can be used to trick machine learning models to misclassify examples by only adding small noise to the input. The <a href="https://www.youtube.com/watch?v=c_5EH3CBtD0">AI Journal has a great video where they show how this could trick self-driving cars</a>.</p>
                                    <p><a href="https://securityintelligence.com/how-can-companies-defend-against-adversarial-machine-learning-attacks-in-the-age-of-ai/">Security intelligence has a great write-up on this</a>, as well as some suggestions on how to protect ourselves. As always with cybersecurity it is impossible to  fully protect from attackers, but it's certainly possible to introduce processes that mitigate basic loopholes.</p>
								</section>
								<section class="4u 6u$(medium) 12u$(xsmall)">
									<span class="icon alt major fa-comment"></span>
                                    <h3>Email sent to the wrong person</h3>
                                    <p>A very large percentage of data breaches are caused due to simple human errors, such as sending the data to the wrong email address. <a href="https://www.mimecast.com/blog/2018/09/most-healthcare-data-breaches-now-caused-by-email/">Mimecast has an interesting article</a> which points out this is the case with very sensitive data in healthcare.</p>
                                    <p>It is important that technologists take into consideration the whole lifecycle of the machine learning algorithm. The process and infrastructure to store the training data, accuracy, documentation, trained model, orchestration of the model, inference results and beyond.</p>
								</section>
                            </div>
                        </div>
                    </div>
                </section>
                
 
                <section id="one" class="spotlight style1 bottom">
                    <span class="image fit main"><img src="images/dots-vision.jpg" alt="" /></span>
					<div class="content">
						<div class="container">
                            <header class="major">
                                <h2>If these principles resonate with you, we invite you to join the <a href="index.html#contact">Ethical ML Network (BETA)</a></h2>
                            </header>
                        </div>
					</div>
				</section>

			<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="https://twitter.com/EthicalML" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
                        <li><a href="https://facebook.com/EthicalML" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
						<li><a href="https://www.linkedin.com/company/the-institute-for-ethical-machine-learning/" class="icon fa-linkedin"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://github.com/EthicalML" class="icon fa-github"><span class="label">GitHub</span></a></li>
                        <li><a href="mailto:a@ethical.institute" class="icon fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; The Institute for Ethical AI & ML. 
                            All rights reserved.</li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-89407852-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-89407852-2');
    </script>


	</body>
</html>
